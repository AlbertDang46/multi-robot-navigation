Logging to /tmp/openai-2024-09-04-09-36-44-564433
Creating dummy env object to get spaces
Loaded the following checkpoint: trained_models/my_model/holonomic/checkpoints/35600.pt
/home/liyiping/anaconda3/envs/CrowdNav2/lib/python3.10/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Box bound precision lowered by casting to float32
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion/CrowdNav_Prediction_AttnGraph/train.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  actor_critic.load_state_dict(torch.load(load_path),strict=False)
/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion/CrowdNav_Prediction_AttnGraph/rl/networks/ogm_rnn.py:946: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  robot_vel_pos_list=[torch.tensor(item).clone().detach() for item in self.robot_vel_pos_deque[robot_index]]
/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion/CrowdNav_Prediction_AttnGraph/rl/networks/ogm_rnn.py:947: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_robot_vel_pos_list=[[torch.tensor(item).clone().detach() for item in self.robot_vel_pos_deque[r]] for r in range(3)]
/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion/CrowdNav_Prediction_AttnGraph/rl/networks/ogm_rnn.py:948: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  lidar_list=[torch.tensor(item).clone().detach() for item in self.lidar_deque[robot_index]]
Predictor Training Loss: 12466.980143229166 KL Loss: 7392.7877197265625 CE Loss: 12393.052083333334
Avg wmse 0.25139811635017395 Avg ssim 0.003924976568669081
Predictor Training Loss: 11783.108723958334 KL Loss: 12643.280680338541 CE Loss: 11656.676106770834
Avg wmse 0.2523200809955597 Avg ssim 0.0034366613253951073
Predictor Training Loss: 11089.133138020834 KL Loss: 1917.2080485026042 CE Loss: 11069.961263020834
Avg wmse 0.251414030790329 Avg ssim 0.003918210510164499
Predictor Training Loss: 10561.294921875 KL Loss: 311.97767639160156 CE Loss: 10558.175130208334
Avg wmse 0.24953143298625946 Avg ssim 0.004747000522911549
Predictor Training Loss: 10058.359049479166 KL Loss: 2036.5324808756511 CE Loss: 10037.993815104166
Avg wmse 0.2505955696105957 Avg ssim 0.004781452473253012
/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion/CrowdNav_Prediction_AttnGraph/rl/networks/ogm_rnn.py:1050: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  robot_vel_pos_list=[torch.tensor(item).clone().detach() for item in self.robot_vel_pos_deque[robot_index]]
/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion/CrowdNav_Prediction_AttnGraph/rl/networks/ogm_rnn.py:1051: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  lidar_list=[torch.tensor(item).clone().detach() for item in self.lidar_deque[robot_index]]
/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion/CrowdNav_Prediction_AttnGraph/rl/networks/ogm_rnn.py:1052: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_robot_vel_pos_list=[[torch.tensor(item).clone().detach() for item in self.robot_vel_pos_deque[r]] for r in range(3)]
Predictor Training Loss: 9307.522135416666 KL Loss: 346.7799479166667 CE Loss: 9304.054036458334
Avg wmse 0.245184063911438 Avg ssim 0.007145153358578682
Predictor Training Loss: 8734.861002604166 KL Loss: 283.5204544067383 CE Loss: 8732.025716145834
Avg wmse 0.24499309062957764 Avg ssim 0.008261754177510738
Predictor Training Loss: 8448.224609375 KL Loss: 3282.4225870768228 CE Loss: 8415.400227864584
Avg wmse 0.25564077496528625 Avg ssim 0.006316691637039185
Predictor Training Loss: 7630.927083333333 KL Loss: 576.3268280029297 CE Loss: 7625.163736979167
Avg wmse 0.25318098068237305 Avg ssim 0.00925376545637846
Predictor Training Loss: 7230.070638020833 KL Loss: 992.6001790364584 CE Loss: 7220.14453125
Avg wmse 0.26877373456954956 Avg ssim 0.006686265114694834
Predictor Training Loss: 6755.53564453125 KL Loss: 605.4954630533854 CE Loss: 6749.480631510417
Avg wmse 0.25565004348754883 Avg ssim 0.011924737133085728
Predictor Training Loss: 6322.54248046875 KL Loss: 433.3491465250651 CE Loss: 6318.208984375
Avg wmse 0.2623274624347687 Avg ssim 0.012495447881519794
Predictor Training Loss: 6023.63037109375 KL Loss: 2330.738972981771 CE Loss: 6000.322916666667
Avg wmse 0.2810947597026825 Avg ssim 0.009338241070508957
Predictor Training Loss: 5677.949544270833 KL Loss: 536.8919982910156 CE Loss: 5672.58056640625
Avg wmse 0.2704964876174927 Avg ssim 0.014433798380196095
Predictor Training Loss: 5361.058919270833 KL Loss: 712.5194905598959 CE Loss: 5353.93359375
Avg wmse 0.2748495042324066 Avg ssim 0.015943070873618126
Predictor Training Loss: 5071.50537109375 KL Loss: 1349.9393107096355 CE Loss: 5058.006022135417
Avg wmse 0.2997036874294281 Avg ssim 0.011174981482326984
Predictor Training Loss: 4901.891438802083 KL Loss: 3710.7655232747397 CE Loss: 4864.78369140625
Avg wmse 0.3126409351825714 Avg ssim 0.008915617130696774
Predictor Training Loss: 4572.224446614583 KL Loss: 1386.9512125651042 CE Loss: 4558.354817708333
Avg wmse 0.3110543489456177 Avg ssim 0.013016077689826488
Predictor Training Loss: 4340.523763020833 KL Loss: 809.3534444173177 CE Loss: 4332.43017578125
Avg wmse 0.3083000183105469 Avg ssim 0.01673249714076519
Predictor Training Loss: 4117.231363932292 KL Loss: 985.4290974934896 CE Loss: 4107.377115885417
Avg wmse 0.3182663917541504 Avg ssim 0.01674600876867771
Predictor Training Loss: 4110.455729166667 KL Loss: 294.3147481282552 CE Loss: 4107.512532552083
Avg wmse 0.3239578902721405 Avg ssim 0.0156489759683609
Predictor Training Loss: 3844.7567545572915 KL Loss: 1243.9349161783855 CE Loss: 3832.3173828125
Avg wmse 0.3413728177547455 Avg ssim 0.013024892657995224
Predictor Training Loss: 3706.1017252604165 KL Loss: 976.4206848144531 CE Loss: 3696.3374837239585
Avg wmse 0.34577664732933044 Avg ssim 0.013627852313220501
Predictor Training Loss: 3584.33251953125 KL Loss: 334.9148254394531 CE Loss: 3580.9833170572915
Avg wmse 0.34375667572021484 Avg ssim 0.017087524756789207
Predictor Training Loss: 3466.4751790364585 KL Loss: 329.67039998372394 CE Loss: 3463.178466796875
Avg wmse 0.3503589630126953 Avg ssim 0.01656246744096279
Predictor Training Loss: 3334.827392578125 KL Loss: 444.5621287027995 CE Loss: 3330.3818359375
Avg wmse 0.358943909406662 Avg ssim 0.01560282427817583
Predictor Training Loss: 3209.0060221354165 KL Loss: 742.5321655273438 CE Loss: 3201.5806477864585
Avg wmse 0.36894741654396057 Avg ssim 0.013847311027348042
Predictor Training Loss: 3088.3968912760415 KL Loss: 230.75225321451822 CE Loss: 3086.0894368489585
Avg wmse 0.36075761914253235 Avg ssim 0.02135307341814041
Predictor Training Loss: 2983.6122233072915 KL Loss: 260.6974131266276 CE Loss: 2981.0052083333335
Avg wmse 0.3637923002243042 Avg ssim 0.022955598309636116
Predictor Training Loss: 2884.0576985677085 KL Loss: 445.0833435058594 CE Loss: 2879.60693359375
Avg wmse 0.36487293243408203 Avg ssim 0.025854462757706642
Predictor Training Loss: 2752.7516276041665 KL Loss: 274.79033915201825 CE Loss: 2750.0037434895835
Avg wmse 0.3624561131000519 Avg ssim 0.02637447416782379
Predictor Training Loss: 2665.7367350260415 KL Loss: 616.6756490071615 CE Loss: 2659.5699869791665
Avg wmse 0.36073818802833557 Avg ssim 0.030235113576054573
Predictor Training Loss: 2589.1639811197915 KL Loss: 809.8871256510416 CE Loss: 2581.065185546875
Avg wmse 0.38145676255226135 Avg ssim 0.02274436689913273
Predictor Training Loss: 2509.0574544270835 KL Loss: 469.4072265625 CE Loss: 2504.3633626302085
Avg wmse 0.38353538513183594 Avg ssim 0.02441146969795227
Predictor Training Loss: 2444.3661295572915 KL Loss: 452.373291015625 CE Loss: 2439.8424479166665
Avg wmse 0.3828938901424408 Avg ssim 0.027127081528306007
Predictor Training Loss: 2379.970947265625 KL Loss: 558.9479777018229 CE Loss: 2374.3815104166665
Avg wmse 0.38940751552581787 Avg ssim 0.026304006576538086
Predictor Training Loss: 2319.5045572916665 KL Loss: 404.5569152832031 CE Loss: 2315.458984375
Avg wmse 0.3823697566986084 Avg ssim 0.0328252948820591
Predictor Training Loss: 2259.3230794270835 KL Loss: 218.51364135742188 CE Loss: 2257.1378580729165
Avg wmse 0.3806039094924927 Avg ssim 0.03666688874363899
Predictor Training Loss: 2199.0581868489585 KL Loss: 252.88548787434897 CE Loss: 2196.529296875
Avg wmse 0.38093698024749756 Avg ssim 0.039655089378356934
Predictor Training Loss: 2169.1708984375 KL Loss: 787.4979248046875 CE Loss: 2161.2959798177085
Avg wmse 0.39492377638816833 Avg ssim 0.03332469239830971
Predictor Training Loss: 2181.7470703125 KL Loss: 472.27415974934894 CE Loss: 2177.0243326822915
Avg wmse 0.399131178855896 Avg ssim 0.032550908625125885
Predictor Training Loss: 2291.2620442708335 KL Loss: 3352.6763509114585 CE Loss: 2257.7352701822915
Avg wmse 0.4047013819217682 Avg ssim 0.02684209682047367
Predictor Training Loss: 2081.895263671875 KL Loss: 520.1661173502604 CE Loss: 2076.693603515625
Avg wmse 0.403678297996521 Avg ssim 0.035654131323099136
Predictor Training Loss: 2097.0889485677085 KL Loss: 145.00696818033853 CE Loss: 2095.638916015625
Avg wmse 0.38315317034721375 Avg ssim 0.04736517369747162
Predictor Training Loss: 2035.5852457682292 KL Loss: 164.3526407877604 CE Loss: 2033.9416910807292
Avg wmse 0.388055682182312 Avg ssim 0.04860233888030052
Predictor Training Loss: 1971.6442464192708 KL Loss: 242.47046915690103 CE Loss: 1969.2195231119792
Avg wmse 0.40189385414123535 Avg ssim 0.04415805637836456
Predictor Training Loss: 1946.3517252604167 KL Loss: 248.4593963623047 CE Loss: 1943.8671468098958
Avg wmse 0.40888357162475586 Avg ssim 0.04092881456017494
Predictor Training Loss: 1911.2354329427083 KL Loss: 181.65424601236978 CE Loss: 1909.4188639322917
Avg wmse 0.41009721159935 Avg ssim 0.0428072027862072
Predictor Training Loss: 1878.8690185546875 KL Loss: 162.17221069335938 CE Loss: 1877.247314453125
Avg wmse 0.40978190302848816 Avg ssim 0.04563978686928749
Predictor Training Loss: 1843.7379557291667 KL Loss: 177.01941935221353 CE Loss: 1841.9677327473958
Avg wmse 0.4092160165309906 Avg ssim 0.049070462584495544
Predictor Training Loss: 1772.0907796223958 KL Loss: 223.37390645345053 CE Loss: 1769.8570149739583
Avg wmse 0.41595908999443054 Avg ssim 0.04237766191363335
Predictor Training Loss: 1749.9736735026042 KL Loss: 233.4115447998047 CE Loss: 1747.6395263671875
Avg wmse 0.4140080213546753 Avg ssim 0.04579811170697212
Predictor Training Loss: 1725.9827473958333 KL Loss: 263.09349568684894 CE Loss: 1723.3517659505208
Avg wmse 0.413153737783432 Avg ssim 0.048192739486694336
Predictor Training Loss: 1701.8809407552083 KL Loss: 307.7179005940755 CE Loss: 1698.8037516276042
Avg wmse 0.4200594127178192 Avg ssim 0.04540696740150452
Predictor Training Loss: 1680.4154866536458 KL Loss: 211.98475138346353 CE Loss: 1678.295654296875
Avg wmse 0.41816964745521545 Avg ssim 0.04818012937903404
Predictor Training Loss: 1655.2379557291667 KL Loss: 185.8279266357422 CE Loss: 1653.379638671875
Avg wmse 0.4169565737247467 Avg ssim 0.051708322018384933
Predictor Training Loss: 1623.8174641927083 KL Loss: 235.63084920247397 CE Loss: 1621.461181640625
Avg wmse 0.4170684814453125 Avg ssim 0.054660405963659286
Predictor Training Loss: 1596.9464925130208 KL Loss: 144.32180786132812 CE Loss: 1595.5032552083333
Avg wmse 0.40981340408325195 Avg ssim 0.06313120573759079
Predictor Training Loss: 1576.5047607421875 KL Loss: 208.935302734375 CE Loss: 1574.4153645833333
Avg wmse 0.4185507297515869 Avg ssim 0.058386143296957016
Predictor Training Loss: 1554.4801839192708 KL Loss: 218.77540079752603 CE Loss: 1552.2924397786458
Avg wmse 0.4158960282802582 Avg ssim 0.06290831416845322
Predictor Training Loss: 1603.4025472005208 KL Loss: 620.646230061849 CE Loss: 1597.1960856119792
Avg wmse 0.4356023371219635 Avg ssim 0.04483560100197792
Predictor Training Loss: 1575.7690836588542 KL Loss: 652.4304402669271 CE Loss: 1569.2447916666667
Avg wmse 0.43422722816467285 Avg ssim 0.04848465323448181
Predictor Training Loss: 1562.4233805338542 KL Loss: 314.32801310221356 CE Loss: 1559.2801106770833
Avg wmse 0.4314506947994232 Avg ssim 0.05201743543148041
Predictor Training Loss: 1543.0817464192708 KL Loss: 224.15229288736978 CE Loss: 1540.8402099609375
Avg wmse 0.42987391352653503 Avg ssim 0.05461111664772034
Predictor Training Loss: 1532.8873697916667 KL Loss: 169.62959798177084 CE Loss: 1531.1910807291667
Avg wmse 0.4306962490081787 Avg ssim 0.054573819041252136
Predictor Training Loss: 1513.2367757161458 KL Loss: 158.84297688802084 CE Loss: 1511.6483561197917
Avg wmse 0.43179699778556824 Avg ssim 0.05598726496100426
Predictor Training Loss: 1495.1663818359375 KL Loss: 252.31585693359375 CE Loss: 1492.6432291666667
Avg wmse 0.4351729154586792 Avg ssim 0.055924784392118454
Predictor Training Loss: 1457.2780354817708 KL Loss: 152.4975789388021 CE Loss: 1455.7530924479167
Avg wmse 0.4232630431652069 Avg ssim 0.06995385140180588
Predictor Training Loss: 1446.6103108723958 KL Loss: 277.8169403076172 CE Loss: 1443.8321940104167
Avg wmse 0.42675697803497314 Avg ssim 0.06898419559001923
Predictor Training Loss: 1425.8997802734375 KL Loss: 211.43439229329428 CE Loss: 1423.785400390625
Avg wmse 0.4175732433795929 Avg ssim 0.07999173551797867
Predictor Training Loss: 1443.2052001953125 KL Loss: 150.86704762776694 CE Loss: 1441.696533203125
Avg wmse 0.4194279611110687 Avg ssim 0.07189097255468369
Predictor Training Loss: 1427.1080322265625 KL Loss: 310.9365743001302 CE Loss: 1423.9986572265625
Avg wmse 0.42915797233581543 Avg ssim 0.06690863519906998
Predictor Training Loss: 1402.7138671875 KL Loss: 170.92831420898438 CE Loss: 1401.0045979817708
Avg wmse 0.42711806297302246 Avg ssim 0.07167039811611176
Predictor Training Loss: 1385.1095377604167 KL Loss: 214.48365783691406 CE Loss: 1382.9646809895833
Avg wmse 0.43476685881614685 Avg ssim 0.06792400032281876
Predictor Training Loss: 1382.0303548177083 KL Loss: 490.7427571614583 CE Loss: 1377.1229248046875
Avg wmse 0.43523597717285156 Avg ssim 0.06830105930566788
Predictor Training Loss: 1365.6030680338542 KL Loss: 141.2479248046875 CE Loss: 1364.1905517578125
Avg wmse 0.43060943484306335 Avg ssim 0.07409084588289261
Predictor Training Loss: 1342.3542073567708 KL Loss: 164.22598775227866 CE Loss: 1340.7119140625
Avg wmse 0.426830917596817 Avg ssim 0.08072606474161148
Predictor Training Loss: 1306.8199055989583 KL Loss: 190.37777201334634 CE Loss: 1304.9161376953125
Avg wmse 0.41536638140678406 Avg ssim 0.09566318988800049
Predictor Training Loss: 1281.6909993489583 KL Loss: 160.68582661946616 CE Loss: 1280.0841471354167
Avg wmse 0.39680707454681396 Avg ssim 0.11401424556970596
Predictor Training Loss: 1264.7357584635417 KL Loss: 172.61396280924478 CE Loss: 1263.0096028645833
Avg wmse 0.3824634552001953 Avg ssim 0.12855176627635956
Predictor Training Loss: 1232.08642578125 KL Loss: 176.975830078125 CE Loss: 1230.316650390625
Avg wmse 0.4106041491031647 Avg ssim 0.08456733822822571
Predictor Training Loss: 1194.1999104817708 KL Loss: 259.4192148844401 CE Loss: 1191.605712890625
Avg wmse 0.4246089458465576 Avg ssim 0.08080396801233292
Predictor Training Loss: 1172.7865397135417 KL Loss: 208.5837656656901 CE Loss: 1170.7007242838542
Avg wmse 0.4336300194263458 Avg ssim 0.0774240717291832
Predictor Training Loss: 1178.2903645833333 KL Loss: 220.34219360351562 CE Loss: 1176.0869547526042
Avg wmse 0.4444367587566376 Avg ssim 0.06866978853940964
Predictor Training Loss: 1172.31005859375 KL Loss: 178.52200826009116 CE Loss: 1170.5248209635417
Avg wmse 0.44585558772087097 Avg ssim 0.06925272196531296
Predictor Training Loss: 1154.474365234375 KL Loss: 171.94881184895834 CE Loss: 1152.7548828125
Avg wmse 0.44499632716178894 Avg ssim 0.07202079892158508
Predictor Training Loss: 1129.0257568359375 KL Loss: 190.31695556640625 CE Loss: 1127.12255859375
Avg wmse 0.43626856803894043 Avg ssim 0.08297678083181381
Predictor Training Loss: 1092.41796875 KL Loss: 193.8999226888021 CE Loss: 1090.4789632161458
Avg wmse 0.4149198830127716 Avg ssim 0.10698244720697403
Predictor Training Loss: 1077.9203287760417 KL Loss: 245.53510538736978 CE Loss: 1075.4650065104167
Avg wmse 0.40817928314208984 Avg ssim 0.11545562744140625
Predictor Training Loss: 1073.0099690755208 KL Loss: 218.63697306315103 CE Loss: 1070.8236083984375
Avg wmse 0.3963104784488678 Avg ssim 0.12609975039958954
Predictor Training Loss: 1318.8201904296875 KL Loss: 275.5985158284505 CE Loss: 1316.064208984375
Avg wmse 0.4360991418361664 Avg ssim 0.08629152923822403
Predictor Training Loss: 1312.0447998046875 KL Loss: 604.7179514567057 CE Loss: 1305.9975992838542
Avg wmse 0.44343820214271545 Avg ssim 0.08133556693792343
Predictor Training Loss: 1293.4978434244792 KL Loss: 347.69446818033856 CE Loss: 1290.0208740234375
Avg wmse 0.44341039657592773 Avg ssim 0.08398935943841934
Predictor Training Loss: 1294.5868326822917 KL Loss: 145.29315185546875 CE Loss: 1293.1339111328125
Avg wmse 0.437898188829422 Avg ssim 0.08934047073125839
Predictor Training Loss: 1282.7528483072917 KL Loss: 145.6182607014974 CE Loss: 1281.296630859375
Avg wmse 0.4386862814426422 Avg ssim 0.08949282765388489
Predictor Training Loss: 1266.3332112630208 KL Loss: 147.5256144205729 CE Loss: 1264.8579508463542
Avg wmse 0.43619656562805176 Avg ssim 0.09387426823377609
Predictor Training Loss: 1243.4523111979167 KL Loss: 137.96539306640625 CE Loss: 1242.0726725260417
Avg wmse 0.42883583903312683 Avg ssim 0.10436191409826279
Predictor Training Loss: 1219.2199300130208 KL Loss: 139.94287109375 CE Loss: 1217.8205159505208
Avg wmse 0.419554203748703 Avg ssim 0.11740630865097046
Predictor Training Loss: 1208.1188557942708 KL Loss: 136.4044647216797 CE Loss: 1206.7548014322917
Avg wmse 0.4116639196872711 Avg ssim 0.1267874389886856
Predictor Training Loss: 1190.8867594401042 KL Loss: 135.9339599609375 CE Loss: 1189.5274251302083
Avg wmse 0.4011121690273285 Avg ssim 0.14180707931518555
Predictor Training Loss: 1376.6411946614583 KL Loss: 169.80994160970053 CE Loss: 1374.943115234375
Avg wmse 0.43410587310791016 Avg ssim 0.09746968746185303
Predictor Training Loss: 1352.9649658203125 KL Loss: 146.3689219156901 CE Loss: 1351.5012613932292
Avg wmse 0.43399372696876526 Avg ssim 0.10240248590707779
Predictor Training Loss: 1348.3743489583333 KL Loss: 582.5607655843099 CE Loss: 1342.5487874348958
Avg wmse 0.4424026310443878 Avg ssim 0.09317433834075928
Predictor Training Loss: 1342.1319986979167 KL Loss: 143.35030619303384 CE Loss: 1340.698486328125
Avg wmse 0.44218742847442627 Avg ssim 0.09457525610923767
Predictor Training Loss: 1341.846435546875 KL Loss: 153.9040730794271 CE Loss: 1340.3074137369792
Avg wmse 0.4424130916595459 Avg ssim 0.09486088156700134
Predictor Training Loss: 1325.4347737630208 KL Loss: 148.31877644856772 CE Loss: 1323.9515787760417
Avg wmse 0.43546661734580994 Avg ssim 0.10395929962396622
Predictor Training Loss: 1300.4623616536458 KL Loss: 149.7224375406901 CE Loss: 1298.9651692708333
Avg wmse 0.4245680272579193 Avg ssim 0.12080534547567368
Predictor Training Loss: 1271.4642333984375 KL Loss: 150.25804646809897 CE Loss: 1269.9616292317708
Avg wmse 0.41137802600860596 Avg ssim 0.14118415117263794
Predictor Training Loss: 1264.9160563151042 KL Loss: 156.0819091796875 CE Loss: 1263.355224609375
Avg wmse 0.4059463441371918 Avg ssim 0.14918985962867737
Predictor Training Loss: 1251.7603352864583 KL Loss: 143.34357198079428 CE Loss: 1250.326904296875
Avg wmse 0.3965494930744171 Avg ssim 0.16215567290782928
Predictor Training Loss: 1251.7603352864583 KL Loss: 143.34357198079428 CE Loss: 1250.326904296875
Avg wmse 0.4255969822406769 Avg ssim 0.12405052781105042.34357198079428 CE Loss: 1250.326904296875
Avg wmse 0.4255969822406769 Avg ssim 0.12405052781105042.34357198079428 CE Loss: 1250.326904296875
Predictor Training Loss: 1335.42529296875 KL Loss: 161.36268615722656 CE Loss: 1333.81168619791675
Predictor Training Loss: 1335.42529296875 KL Loss: 161.36268615722656 CE Loss: 1333.81168619791675
Predictor Training Loss: 1335.42529296875 KL Loss: 161.36268615722656 CE Loss: 1333.81168619791675
Avg wmse 0.44674840569496155 Avg ssim 0.10676613450050354268615722656 CE Loss: 1333.81168619791675
Avg wmse 0.44674840569496155 Avg ssim 0.10676613450050354268615722656 CE Loss: 1333.81168619791675
Predictor Training Loss: 1403.8261311848958 KL Loss: 169.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Avg wmse 0.44221031665802 Avg ssim 0.1104567423462867769.00360616048178 CE Loss: 1402.1361083984375
Predictor Training Loss: 1341.6129964192708 KL Loss: 166.55519104003906 CE Loss: 1339.9474690755208
Predictor Training Loss: 1341.6129964192708 KL Loss: 166.55519104003906 CE Loss: 1339.9474690755208
Predictor Training Loss: 1341.6129964192708 KL Loss: 166.55519104003906 CE Loss: 1339.9474690755208
Predictor Training Loss: 1341.6129964192708 KL Loss: 166.55519104003906 CE Loss: 1339.9474690755208
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Predictor Training Loss: 1284.3175455729167 KL Loss: 173.13292439778647 CE Loss: 1282.5862223307292
Traceback (most recent call last):
  File "/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion/CrowdNav_Prediction_AttnGraph/train.py", line 368, in <module>
    main()
  File "/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion/CrowdNav_Prediction_AttnGraph/train.py", line 232, in main
    obs, rewards, done, infos= envs.step(all_actions)
  File "/home/liyiping/dev/MARL2_check_ogm_obst_/CrowdNav_Prediction_AttnGraph/baselines/baselines/common/vec_env/vec_env.py", line 108, in step
    return self.step_wait()
  File "/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion/CrowdNav_Prediction_AttnGraph/rl/networks/envs.py", line 224, in step_wait
    obs[key] = torch.from_numpy(obs[key]).to(self.device)
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.