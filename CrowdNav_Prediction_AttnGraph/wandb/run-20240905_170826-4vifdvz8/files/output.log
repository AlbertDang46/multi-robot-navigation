Logging to /tmp/openai-2024-09-05-17-08-29-942746
Creating dummy env object to get spaces
Loaded the following checkpoint: trained_models/my_model/holonomic/checkpoints/35600.pt
/home/liyiping/anaconda3/envs/CrowdNav2/lib/python3.10/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Box bound precision lowered by casting to float32
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion_coordination/CrowdNav_Prediction_AttnGraph/train.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  actor_critic.load_state_dict(torch.load(load_path),strict=False)
/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion_coordination/CrowdNav_Prediction_AttnGraph/rl/networks/ogm_rnn.py:878: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  robot_vel_pos_list=[torch.tensor(item).clone().detach() for item in self.robot_vel_pos_deque[robot_index]]
/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion_coordination/CrowdNav_Prediction_AttnGraph/rl/networks/ogm_rnn.py:880: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  lidar_list=[torch.tensor(item).clone().detach() for item in self.lidar_deque[robot_index]]
Predictor Training Loss: 12793.9775390625 KL Loss: 66542.90584309895 CE Loss: 12128.548502604166
Avg wmse 0.252221018075943 Avg ssim 0.004437420982867479
Predictor Training Loss: 11800.227213541666 KL Loss: 9223.278483072916 CE Loss: 11707.994140625
Avg wmse 0.24600742757320404 Avg ssim 0.005160169210284948
Predictor Training Loss: 11163.262044270834 KL Loss: 688.1382039388021 CE Loss: 11156.380533854166
Avg wmse 0.24440604448318481 Avg ssim 0.005440435837954283
Predictor Training Loss: 10698.709635416666 KL Loss: 4401.832102457683 CE Loss: 10654.691080729166
Avg wmse 0.24396724998950958 Avg ssim 0.005288245156407356
/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion_coordination/CrowdNav_Prediction_AttnGraph/rl/networks/ogm_rnn.py:940: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  robot_vel_pos_list=[torch.tensor(item).clone().detach() for item in self.robot_vel_pos_deque[robot_index]]
/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion_coordination/CrowdNav_Prediction_AttnGraph/rl/networks/ogm_rnn.py:941: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  lidar_list=[torch.tensor(item).clone().detach() for item in self.lidar_deque[robot_index]]
Predictor Training Loss: 9878.072265625 KL Loss: 334.18031819661456 CE Loss: 9874.73046875
Avg wmse 0.2382822483778 Avg ssim 0.006994351744651794
Predictor Training Loss: 9338.531901041666 KL Loss: 1329.1813557942708 CE Loss: 9325.240559895834
Avg wmse 0.24222619831562042 Avg ssim 0.0068418774753808975
Predictor Training Loss: 8762.213541666666 KL Loss: 1669.4443969726562 CE Loss: 8745.519205729166
Avg wmse 0.2375628799200058 Avg ssim 0.008724170736968517
Predictor Training Loss: 8083.81884765625 KL Loss: 973.9044698079427 CE Loss: 8074.079915364583
Avg wmse 0.23606832325458527 Avg ssim 0.010234665125608444
Predictor Training Loss: 7553.616048177083 KL Loss: 622.8611551920573 CE Loss: 7547.387532552083
Avg wmse 0.22854948043823242 Avg ssim 0.012624017894268036
Predictor Training Loss: 7052.659993489583 KL Loss: 866.2392985026041 CE Loss: 7043.997395833333
Avg wmse 0.2338225394487381 Avg ssim 0.013386155478656292
Predictor Training Loss: 6740.08837890625 KL Loss: 455.55877685546875 CE Loss: 6735.532877604167
Avg wmse 0.22565902769565582 Avg ssim 0.017826585099101067
Predictor Training Loss: 6305.679850260417 KL Loss: 891.0921936035156 CE Loss: 6296.768880208333
Avg wmse 0.23873436450958252 Avg ssim 0.017563892528414726
Predictor Training Loss: 5853.187337239583 KL Loss: 1064.8408813476562 CE Loss: 5842.538736979167
Avg wmse 0.2567651867866516 Avg ssim 0.01618025451898575
Predictor Training Loss: 5550.035807291667 KL Loss: 1345.6159057617188 CE Loss: 5536.579752604167
Avg wmse 0.26703333854675293 Avg ssim 0.016150010749697685
Predictor Training Loss: 5215.645670572917 KL Loss: 1446.8504028320312 CE Loss: 5201.177083333333
Avg wmse 0.2766554057598114 Avg ssim 0.01665611006319523
Predictor Training Loss: 4936.943033854167 KL Loss: 1202.6900227864583 CE Loss: 4924.916178385417
Avg wmse 0.28005102276802063 Avg ssim 0.018406013026833534
Predictor Training Loss: 4678.636555989583 KL Loss: 1228.337158203125 CE Loss: 4666.353190104167
Avg wmse 0.28233733773231506 Avg ssim 0.020753342658281326
Predictor Training Loss: 4517.962565104167 KL Loss: 470.4329833984375 CE Loss: 4513.25830078125
Avg wmse 0.2549089789390564 Avg ssim 0.030837679281830788
Predictor Training Loss: 4232.532389322917 KL Loss: 789.9633992513021 CE Loss: 4224.6328125
Avg wmse 0.28560128808021545 Avg ssim 0.025631381198763847
Predictor Training Loss: 4030.5126953125 KL Loss: 1140.8681030273438 CE Loss: 4019.10400390625
Avg wmse 0.29645344614982605 Avg ssim 0.025487815961241722
Predictor Training Loss: 3887.0465494791665 KL Loss: 428.16368611653644 CE Loss: 3882.764892578125
Avg wmse 0.2930571734905243 Avg ssim 0.031447459012269974
Predictor Training Loss: 3792.906494140625 KL Loss: 1878.175537109375 CE Loss: 3774.124755859375
Avg wmse 0.31178519129753113 Avg ssim 0.025991996750235558
Predictor Training Loss: 3556.3562825520835 KL Loss: 523.5209248860677 CE Loss: 3551.12109375
Avg wmse 0.29918554425239563 Avg ssim 0.03623497113585472
Predictor Training Loss: 3383.419677734375 KL Loss: 701.7443135579427 CE Loss: 3376.4022623697915
Avg wmse 0.3009437918663025 Avg ssim 0.03777043893933296
Predictor Training Loss: 3249.7704264322915 KL Loss: 892.7548624674479 CE Loss: 3240.8428548177085
Avg wmse 0.3010283410549164 Avg ssim 0.040088631212711334
Predictor Training Loss: 3154.2600911458335 KL Loss: 1023.4078165690104 CE Loss: 3144.0259602864585
Avg wmse 0.2999618351459503 Avg ssim 0.04282079637050629
Predictor Training Loss: 3034.35546875 KL Loss: 402.9178059895833 CE Loss: 3030.3263346354165
Avg wmse 0.28746557235717773 Avg ssim 0.05330991744995117
Predictor Training Loss: 2983.5619303385415 KL Loss: 310.95716349283856 CE Loss: 2980.452392578125
Avg wmse 0.29595354199409485 Avg ssim 0.054377779364585876
Predictor Training Loss: 2921.5296223958335 KL Loss: 1101.5172627766926 CE Loss: 2910.5144856770835
Avg wmse 0.3339984118938446 Avg ssim 0.03946718946099281
Predictor Training Loss: 2755.9462076822915 KL Loss: 299.4278259277344 CE Loss: 2752.951904296875
Avg wmse 0.3182450234889984 Avg ssim 0.05432208999991417
Predictor Training Loss: 2581.4649251302085 KL Loss: 265.0289306640625 CE Loss: 2578.814697265625
Avg wmse 0.32471147179603577 Avg ssim 0.044110994786024094
Predictor Training Loss: 2490.0589192708335 KL Loss: 483.99439493815106 CE Loss: 2485.218994140625
Avg wmse 0.33647242188453674 Avg ssim 0.04292840138077736
Predictor Training Loss: 2399.7967936197915 KL Loss: 455.3688456217448 CE Loss: 2395.2430826822915
Avg wmse 0.3406928479671478 Avg ssim 0.04473763704299927
Predictor Training Loss: 2334.3056640625 KL Loss: 288.7290344238281 CE Loss: 2331.4183756510415
Avg wmse 0.3344006836414337 Avg ssim 0.05014462396502495
Predictor Training Loss: 2267.8995768229165 KL Loss: 405.36647542317706 CE Loss: 2263.845947265625
Avg wmse 0.3370426595211029 Avg ssim 0.05170217156410217
Predictor Training Loss: 2192.5498860677085 KL Loss: 338.1367492675781 CE Loss: 2189.1685384114585
Avg wmse 0.3202129900455475 Avg ssim 0.06336554139852524
Predictor Training Loss: 2138.6097005208335 KL Loss: 426.60540771484375 CE Loss: 2134.3436686197915
Avg wmse 0.3383048474788666 Avg ssim 0.058123696595430374
Predictor Training Loss: 2078.8018391927085 KL Loss: 390.3986104329427 CE Loss: 2074.8978678385415
Avg wmse 0.34457293152809143 Avg ssim 0.05798867344856262
Predictor Training Loss: 2029.8648681640625 KL Loss: 490.07615152994794 CE Loss: 2024.964111328125
Avg wmse 0.34227728843688965 Avg ssim 0.06214507296681404
Predictor Training Loss: 1971.7797037760417 KL Loss: 348.66676839192706 CE Loss: 1968.2930501302083
Avg wmse 0.34743165969848633 Avg ssim 0.06354622542858124
Predictor Training Loss: 1938.5797119140625 KL Loss: 735.0535888671875 CE Loss: 1931.2291666666667
Avg wmse 0.3626958429813385 Avg ssim 0.05759115517139435
Predictor Training Loss: 1888.3971354166667 KL Loss: 593.3747151692709 CE Loss: 1882.4634195963542
Avg wmse 0.34821709990501404 Avg ssim 0.06826642155647278
Predictor Training Loss: 1834.95947265625 KL Loss: 461.22584025065106 CE Loss: 1830.3472086588542
Avg wmse 0.3358058035373688 Avg ssim 0.07884598523378372
Predictor Training Loss: 1765.6644694010417 KL Loss: 428.35426839192706 CE Loss: 1761.3809000651042
Avg wmse 0.3277462422847748 Avg ssim 0.08208995312452316
Predictor Training Loss: 1708.064208984375 KL Loss: 418.080078125 CE Loss: 1703.8834228515625
Avg wmse 0.3355708420276642 Avg ssim 0.0801997110247612
Predictor Training Loss: 1669.3939208984375 KL Loss: 378.4342447916667 CE Loss: 1665.6095784505208
Avg wmse 0.3500288426876068 Avg ssim 0.07609064877033234
Predictor Training Loss: 1657.4746907552083 KL Loss: 290.2384084065755 CE Loss: 1654.5723063151042
Avg wmse 0.35258999466896057 Avg ssim 0.0770639181137085
Predictor Training Loss: 1643.0143636067708 KL Loss: 194.55160013834634 CE Loss: 1641.06884765625
Avg wmse 0.3573281764984131 Avg ssim 0.07878110557794571
Predictor Training Loss: 1608.5629475911458 KL Loss: 205.54834493001303 CE Loss: 1606.5074462890625
Avg wmse 0.36798548698425293 Avg ssim 0.07601135224103928
Predictor Training Loss: 1577.8221435546875 KL Loss: 225.0174763997396 CE Loss: 1575.5719807942708
Avg wmse 0.36219286918640137 Avg ssim 0.08197728544473648
Predictor Training Loss: 1557.2657470703125 KL Loss: 581.3428039550781 CE Loss: 1551.4523518880208
Avg wmse 0.36334213614463806 Avg ssim 0.08875159174203873
Predictor Training Loss: 1524.6676839192708 KL Loss: 453.71120198567706 CE Loss: 1520.130615234375
Avg wmse 0.3539820909500122 Avg ssim 0.09800929576158524
Predictor Training Loss: 1491.5730387369792 KL Loss: 402.2852478027344 CE Loss: 1487.5502115885417
Avg wmse 0.3471301794052124 Avg ssim 0.1061621829867363
Predictor Training Loss: 1494.059814453125 KL Loss: 355.9211832682292 CE Loss: 1490.5005696614583
Avg wmse 0.3367673456668854 Avg ssim 0.11645627021789551
Predictor Training Loss: 1459.9839680989583 KL Loss: 330.3874969482422 CE Loss: 1456.6800944010417
Avg wmse 0.3430635631084442 Avg ssim 0.12143290042877197
Predictor Training Loss: 1437.1736653645833 KL Loss: 244.9344228108724 CE Loss: 1434.7242838541667
Avg wmse 0.3323810398578644 Avg ssim 0.13184797763824463
Predictor Training Loss: 1420.6680094401042 KL Loss: 267.08587646484375 CE Loss: 1417.9971516927083
Avg wmse 0.33904826641082764 Avg ssim 0.1304413229227066
Predictor Training Loss: 1405.7412923177083 KL Loss: 340.46360270182294 CE Loss: 1402.3366292317708
Avg wmse 0.3438871204853058 Avg ssim 0.13086549937725067
Predictor Training Loss: 1377.7103678385417 KL Loss: 362.02427164713544 CE Loss: 1374.0901285807292
Avg wmse 0.3417172431945801 Avg ssim 0.13704103231430054
Predictor Training Loss: 1359.4351806640625 KL Loss: 329.2810465494792 CE Loss: 1356.1423746744792
Avg wmse 0.34746479988098145 Avg ssim 0.1361241191625595
Avg wmse 0.3254641592502594 Avg ssim 0.17820848524570465.46360270182294 CE Loss: 1402.3366292317708
Predictor Training Loss: 1328.7266031901042 KL Loss: 372.1309051513672 CE Loss: 1325.0052897135417
Avg wmse 0.3477456569671631 Avg ssim 0.1642151027917862
Avg wmse 0.3254641592502594 Avg ssim 0.17820848524570465.46360270182294 CE Loss: 1402.3366292317708
Avg wmse 0.3254641592502594 Avg ssim 0.17820848524570465.46360270182294 CE Loss: 1402.3366292317708
Predictor Training Loss: 1214.9278157552083 KL Loss: 201.9080047607422 CE Loss: 1212.90873209635428
Avg wmse 0.3017233908176422 Avg ssim 0.26349082589149475.9080047607422 CE Loss: 1212.90873209635428
Avg wmse 0.3017233908176422 Avg ssim 0.26349082589149475.9080047607422 CE Loss: 1212.90873209635428
Predictor Training Loss: 1180.7708740234375 KL Loss: 199.28857930501303 CE Loss: 1178.7779947916667
Avg wmse 0.3163985311985016 Avg ssim 0.2686787545681 199.28857930501303 CE Loss: 1178.7779947916667
Avg wmse 0.3163985311985016 Avg ssim 0.2686787545681 199.28857930501303 CE Loss: 1178.7779947916667
Predictor Training Loss: 1104.9032796223958 KL Loss: 248.69945780436197 CE Loss: 1102.4162597656257
Avg wmse 0.3370518982410431 Avg ssim 0.26132202148437548.69945780436197 CE Loss: 1102.4162597656257
Avg wmse 0.3370518982410431 Avg ssim 0.26132202148437548.69945780436197 CE Loss: 1102.4162597656257
Predictor Training Loss: 993.3550821940104 KL Loss: 273.27784220377606 CE Loss: 990.622294108072957
Avg wmse 0.3052646219730377 Avg ssim 0.3333932459354400627784220377606 CE Loss: 990.622294108072957
Avg wmse 0.3052646219730377 Avg ssim 0.3333932459354400627784220377606 CE Loss: 990.622294108072957
Predictor Training Loss: 758.7029622395834 KL Loss: 306.99310302734375 CE Loss: 755.633015950520957
Avg wmse 0.31461769342422485 Avg ssim 0.318820029497146699310302734375 CE Loss: 755.633015950520957
Avg wmse 0.3013937175273895 Avg ssim 0.3602295219898224699310302734375 CE Loss: 755.633015950520957
Avg wmse 0.3013937175273895 Avg ssim 0.3602295219898224699310302734375 CE Loss: 755.633015950520957
Avg wmse 0.3013937175273895 Avg ssim 0.3602295219898224699310302734375 CE Loss: 755.633015950520957
Avg wmse 0.2743896543979645 Avg ssim 0.4237769842147827699310302734375 CE Loss: 755.633015950520957
Avg wmse 0.2743896543979645 Avg ssim 0.4237769842147827699310302734375 CE Loss: 755.633015950520957
Avg wmse 0.2743896543979645 Avg ssim 0.4237769842147827699310302734375 CE Loss: 755.633015950520957
Avg wmse 0.30735546350479126 Avg ssim 0.386059671640396199310302734375 CE Loss: 755.633015950520957
Predictor Training Loss: 794.1736043294271 KL Loss: 307.3641764322917 CE Loss: 791.0999552408854957
Predictor Training Loss: 794.1736043294271 KL Loss: 307.3641764322917 CE Loss: 791.0999552408854957
Predictor Training Loss: 794.1736043294271 KL Loss: 307.3641764322917 CE Loss: 791.0999552408854957
Avg wmse 0.2671174705028534 Avg ssim 0.4330810606479645.3641764322917 CE Loss: 791.0999552408854957
Avg wmse 0.2671174705028534 Avg ssim 0.4330810606479645.3641764322917 CE Loss: 791.0999552408854957
Avg wmse 0.2668387293815613 Avg ssim 0.4427633285522461.3641764322917 CE Loss: 791.0999552408854957
Avg wmse 0.2668387293815613 Avg ssim 0.4427633285522461.3641764322917 CE Loss: 791.0999552408854957
Avg wmse 0.28099194169044495 Avg ssim 0.43510186672210693641764322917 CE Loss: 791.0999552408854957
Predictor Training Loss: 759.3868001302084 KL Loss: 343.2368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.27374550700187683 Avg ssim 0.43254813551902772368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.27374550700187683 Avg ssim 0.43254813551902772368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.27000391483306885 Avg ssim 0.44649517536163332368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.27000391483306885 Avg ssim 0.44649517536163332368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.27333375811576843 Avg ssim 0.44447720050811772368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.27333375811576843 Avg ssim 0.44447720050811772368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.25985145568847656 Avg ssim 0.45132353901863172368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.25985145568847656 Avg ssim 0.45132353901863172368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.25985145568847656 Avg ssim 0.45132353901863172368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.2557388246059418 Avg ssim 0.475025087594985962368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.2557388246059418 Avg ssim 0.475025087594985962368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.27174392342567444 Avg ssim 0.45684549212455752368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.2497926950454712 Avg ssim 0.491204589605331452368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.2497926950454712 Avg ssim 0.491204589605331452368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.2497926950454712 Avg ssim 0.491204589605331452368570963542 CE Loss: 755.9544270833334957
Avg wmse 0.23855988681316376 Avg ssim 0.52408742904663092368570963542 CE Loss: 755.9544270833334957
Predictor Training Loss: 752.5413004557291 KL Loss: 377.2624206542969 CE Loss: 748.7686564127604957
Avg wmse 0.20611076056957245 Avg ssim 0.56044697761535642624206542969 CE Loss: 748.7686564127604957
Avg wmse 0.20611076056957245 Avg ssim 0.56044697761535642624206542969 CE Loss: 748.7686564127604957
Avg wmse 0.25299134850502014 Avg ssim 0.49562749266624452624206542969 CE Loss: 748.7686564127604957
Avg wmse 0.25299134850502014 Avg ssim 0.49562749266624452624206542969 CE Loss: 748.7686564127604957
Avg wmse 0.23123474419116974 Avg ssim 0.52940869331359862624206542969 CE Loss: 748.7686564127604957
Avg wmse 0.23123474419116974 Avg ssim 0.52940869331359862624206542969 CE Loss: 748.7686564127604957
Avg wmse 0.22569262981414795 Avg ssim 0.54610306024551392624206542969 CE Loss: 748.7686564127604957
Avg wmse 0.22569262981414795 Avg ssim 0.54610306024551392624206542969 CE Loss: 748.7686564127604957
Avg wmse 0.21542902290821075 Avg ssim 0.56504702568054292624206542969 CE Loss: 748.7686564127604957
Predictor Training Loss: 579.5188802083334 KL Loss: 386.1890563964844 CE Loss: 575.6569824218754957
Predictor Training Loss: 579.5188802083334 KL Loss: 386.1890563964844 CE Loss: 575.6569824218754957
Predictor Training Loss: 579.5188802083334 KL Loss: 386.1890563964844 CE Loss: 575.6569824218754957
Avg wmse 0.19805128872394562 Avg ssim 0.60702681541442871890563964844 CE Loss: 575.6569824218754957
Predictor Training Loss: 635.8352661132812 KL Loss: 390.2765604654948 CE Loss: 631.9324951171875957
Predictor Training Loss: 635.8352661132812 KL Loss: 390.2765604654948 CE Loss: 631.9324951171875957
Avg wmse 0.21898530423641205 Avg ssim 0.55867546796798712765604654948 CE Loss: 631.9324951171875957
Avg wmse 0.21898530423641205 Avg ssim 0.55867546796798712765604654948 CE Loss: 631.9324951171875957
Avg wmse 0.2227005511522293 Avg ssim 0.550419270992279712765604654948 CE Loss: 631.9324951171875957
Avg wmse 0.2227005511522293 Avg ssim 0.550419270992279712765604654948 CE Loss: 631.9324951171875957
Avg wmse 0.2227005511522293 Avg ssim 0.550419270992279712765604654948 CE Loss: 631.9324951171875957
Avg wmse 0.2154272049665451 Avg ssim 0.569772660732269312765604654948 CE Loss: 631.9324951171875957
Avg wmse 0.2154272049665451 Avg ssim 0.569772660732269312765604654948 CE Loss: 631.9324951171875957
Avg wmse 0.22849704325199127 Avg ssim 0.55402874946594242765604654948 CE Loss: 631.9324951171875957
Predictor Training Loss: 629.9153238932291 KL Loss: 390.38219197591144 CE Loss: 626.011515299479157
Avg wmse 0.2080516219139099 Avg ssim 0.5951626896858215.38219197591144 CE Loss: 626.011515299479157
Avg wmse 0.2080516219139099 Avg ssim 0.5951626896858215.38219197591144 CE Loss: 626.011515299479157
Avg wmse 0.23594160377979279 Avg ssim 0.539236128330230738219197591144 CE Loss: 626.011515299479157
Predictor Training Loss: 708.5609537760416 KL Loss: 363.58265177408856 CE Loss: 704.925109863281257
Predictor Training Loss: 708.5609537760416 KL Loss: 363.58265177408856 CE Loss: 704.925109863281257
Avg wmse 0.22834868729114532 Avg ssim 0.532320737838745158265177408856 CE Loss: 704.925109863281257
Avg wmse 0.22834868729114532 Avg ssim 0.532320737838745158265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23201997578144073 Avg ssim 0.547261059284210258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23201997578144073 Avg ssim 0.547261059284210258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23201997578144073 Avg ssim 0.547261059284210258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Avg wmse 0.23502814769744873 Avg ssim 0.539975583553314258265177408856 CE Loss: 704.925109863281257
Traceback (most recent call last):
  File "/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion_coordination/CrowdNav_Prediction_AttnGraph/train.py", line 368, in <module>
    main()
  File "/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion_coordination/CrowdNav_Prediction_AttnGraph/train.py", line 232, in main
    obs, rewards, done, infos= envs.step(all_actions)
  File "/home/liyiping/dev/MARL2_check_ogm_obst_/CrowdNav_Prediction_AttnGraph/baselines/baselines/common/vec_env/vec_env.py", line 108, in step
    return self.step_wait()
  File "/home/liyiping/dev/ogm_pred/ogm_sogmp_trans_pos_middle_fusion_coordination/CrowdNav_Prediction_AttnGraph/rl/networks/envs.py", line 224, in step_wait
    obs[key] = torch.from_numpy(obs[key]).to(self.device)
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.